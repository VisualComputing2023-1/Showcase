<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Introduction on Visual Computing 2023-1</title><link>https://visualcomputing2023-1.github.io/Showcase/</link><description>Recent content in Introduction on Visual Computing 2023-1</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://visualcomputing2023-1.github.io/Showcase/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://visualcomputing2023-1.github.io/Showcase/docs/Color-mapping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing2023-1.github.io/Showcase/docs/Color-mapping/</guid><description>Color mapping applications # Exercise
Implement a color mapping application that helps people who are color blind see the colors around them. Introduction # In this exercise we are going to show how a colorblind person can perceive the colors in the real world.
Color Mapping # A color map is a set of values that are associated with colors. Generally is used to display a single brand raster consistenly with the same colors.</description></item><item><title/><link>https://visualcomputing2023-1.github.io/Showcase/docs/Color-models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing2023-1.github.io/Showcase/docs/Color-models/</guid><description>Color models # Exercise
Research other color models such as HSL, HSB, XYZ. Introduction # The visualisation of colors is a pretty simple theme when done automatically by the human eye. However, when thinking more about its mechanism, it gets more complicated. To simplify its understanding for humans, many color models have been defined through the years. Two main categories of color models exist : additive color models and substractive color models.</description></item><item><title/><link>https://visualcomputing2023-1.github.io/Showcase/docs/Depth-Perception/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing2023-1.github.io/Showcase/docs/Depth-Perception/</guid><description>Depth Perception with Monocular Cues # Introduction # Depth perception is a crucial aspect of human vision, allowing us to perceive the distance and spatial relationships between objects in our environment. While binocular vision, which relies on the slightly different perspectives provided by each eye, is an important factor in depth perception, monocular cues can also provide valuable depth information. In this report, we&amp;rsquo;ll explore some of the different types of monocular cues, their applications, and how they contribute to our ability to perceive the 3D world around us.</description></item><item><title/><link>https://visualcomputing2023-1.github.io/Showcase/docs/Terrain-generation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing2023-1.github.io/Showcase/docs/Terrain-generation/</guid><description>Terrain generation # Exercise
Develop a terrain visualization application. Check out the 3D terrain generation with Perlin noise coding train tutorial. Main objectives # The aim of this exercise is to develop an automatic terrain generator, that would be useable in games or for visual effects in general. In that sense, it is important to develop features that serve that aim, while controlling :
the &amp;ldquo;relief&amp;rdquo; of the terrain, to be able to develop a large range of terrains the direction of the movement of the camera, in cases where we would want to generate a moving terrain (plane trips, panoramas, view of the landscape, &amp;hellip;) the camera speed, still in an aim to control the cinematics the visualisation or not of the latices, to eventually correct certain parts of the terrain the colors of the terrain, for the user to be able to control therender of the terrain.</description></item></channel></rss>